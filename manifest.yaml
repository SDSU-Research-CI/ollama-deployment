apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama
  labels:
    k8s-app: ollama
spec:
  replicas: 1
  selector:
    matchLabels:
      k8s-app: ollama
  template:
    metadata:
      labels:
        k8s-app: ollama
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: nautilus.io/csu-tide
                operator: Exists
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - NVIDIA-A100-80GB-PCIe
      containers:
      - name: pod-ollama
        # image: "ollama/ollama:0.1.34"
        image: "kkricksdsu/ollama:v1.1"
        # command: ["ollama", "serve"]
        command: ["bash", "-c", "systemctl daemon-reload && systemctl enable ollama && systemctl start ollama"]
        ports:
        - containerPort: 11434
        resources:
          limits:
            memory: 16Gi
            cpu: 4
            nvidia.com/a100: 1
          requests:
            memory: 16Gi
            cpu: 4
            nvidia.com/a100: 1
        volumeMounts:
        - name: pvc-ollama
          mountPath: /usr/share/ollama/.ollama/
      - name: ollama-proxy
        image: "kkricksdsu/ollama-proxy:v1.0"
        command: ["bash", "-c", "python3 ollama_proxy_server/main.py --config /etc/ollama/config/config.ini --users_list /etc/ollama/users/authorized_users.txt --port 8080"]
        ports:
        - containerPort: 8080
        resources:
          limits:
            memory: 2Gi
            cpu: 2
          requests:
            memory: 2Gi
            cpu: 2
        volumeMounts:
        - name: ollama-proxy-config
          mountPath: /etc/ollama/config
        - name: ollama-proxy-users
          mountPath: /etc/ollama/users
      tolerations:
      - effect: NoSchedule
        key: nautilus.io/sdsu-fix
        operator: Exists
      - effect: NoSchedule
        key: nautilus.io/csu-tide
        operator: Exists
      volumes:
      - name: pvc-ollama
        persistentVolumeClaim:
          claimName: ollama
      - name: ollama-proxy-config
        secret:
          secretName: ollama-proxy-config
      - name: ollama-proxy-users
        secret:
          secretName: ollama-proxy-users

---

apiVersion: v1
kind: Service
metadata:
  name: ollama-service
spec:
  selector:
    k8s-app: ollama
  ports:
  - name: ollama
    protocol: TCP
    port: 11434
    targetPort: 11434
  - name: ollama-proxy
    protocol: TCP
    port: 80
    targetPort: 8080

  type: ClusterIP

---

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    kubernetes.io/ingress.class: haproxy
    ingress.kubernetes.io/allowlist-source-range: "130.191.0.0/16, 146.244.0.0/16"
  name: ollama-ingress
spec:
  rules:
  - host: sdsu-jsbaic-ollama.nrp-nautilus.io
    http:
      paths:
      - backend:
          service:
            name: ollama-service
            port:
              number: 80
        path: /
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - sdsu-jsbaic-ollama.nrp-nautilus.io
